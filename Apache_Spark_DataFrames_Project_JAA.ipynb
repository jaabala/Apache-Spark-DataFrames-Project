{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Apache Spark DataFrames Project - JAA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr26f7K4sxIE"
      },
      "source": [
        "# Apache Spark DataFrames Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UGu9BgEs7iP"
      },
      "source": [
        "## 1. Data Importation and Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh5NCoc8fsSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "006de80b-c2fe-44bf-db2b-f2a364014bcf"
      },
      "source": [
        "# To use Pyspark , We'll first install it\n",
        "# ---\n",
        "#\n",
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.2.1)\n",
            "Requirement already satisfied: py4j==0.10.9.3 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xAks71g32G7"
      },
      "source": [
        "# Next, we'll run a local spark session\n",
        "# ---\n",
        "#\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preview the first few rows\n",
        "\n",
        "\n",
        "with open('saf_stock.csv') as f:\n",
        "  for x in range(0,4):\n",
        "    print(f.readline())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF5m84kQRoFO",
        "outputId": "43615a33-4b5a-4ae4-eed0-c2f97fadad94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date,Open,High,Low,Close,Volume,Adj Close\n",
            "\n",
            "2012-01-03,59.970001,61.060001,59.869999,60.330002,12668800,52.619234999999996\n",
            "\n",
            "2012-01-04,60.209998999999996,60.349998,59.470001,59.709998999999996,9593300,52.078475\n",
            "\n",
            "2012-01-05,59.349998,59.619999,58.369999,59.419998,12768200,51.825539\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN321zekGt17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe5aa301-ed21-4c15-a74b-311e056fddd6"
      },
      "source": [
        "# To begin working, we'll load our data set into an RDD\n",
        "# ---\n",
        "# Dataset Download URL =  https://bit.ly/3pmchka\n",
        "# Hint: Download and upload the file to colab\n",
        "# ---\n",
        "#\n",
        "from pyspark.sql import SQLContext\n",
        "\n",
        "# Pass in the SparkContext object `sc`\n",
        "sqlCtx = SQLContext(sc)\n",
        "\n",
        "# Read CSV data into a DataFrame object `df`\n",
        "df = sqlCtx.read.csv(\"saf_stock.csv\",header=True, inferSchema = True)\n",
        "\n",
        "# Print the type\n",
        "print(type(df))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:79: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.sql.dataframe.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#next we will determine the column names and infer the data types \n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFXnvcZMNvT_",
        "outputId": "f0dc317b-3dbd-47d9-c767-dc45bba964a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Open: double (nullable = true)\n",
            " |-- High: double (nullable = true)\n",
            " |-- Low: double (nullable = true)\n",
            " |-- Close: double (nullable = true)\n",
            " |-- Volume: integer (nullable = true)\n",
            " |-- Adj Close: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Schema Observations:\n",
        "1. There are 7 columns within the spark dataframe\n",
        "2. all fields are nullable, meaning they cannot contain null values\n",
        "3. the date column is in string format while volume column is an integer owing to the lack of decimal points"
      ],
      "metadata": {
        "id": "kEtvXPDXTMKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Next we will display the first 5 records\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFuBERvzTJNN",
        "outputId": "9165efd1-4377-427e-c60c-d71a1c54db7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
            "|      Date|              Open|     High|      Low|             Close|  Volume|         Adj Close|\n",
            "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
            "|2012-01-03|         59.970001|61.060001|59.869999|         60.330002|12668800|52.619234999999996|\n",
            "|2012-01-04|60.209998999999996|60.349998|59.470001|59.709998999999996| 9593300|         52.078475|\n",
            "|2012-01-05|         59.349998|59.619999|58.369999|         59.419998|12768200|         51.825539|\n",
            "|2012-01-06|         59.419998|59.450001|58.869999|              59.0| 8069400|          51.45922|\n",
            "|2012-01-09|         59.029999|59.549999|58.919998|             59.18| 6679300|51.616215000000004|\n",
            "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Finally, under exploration we will use the describe method to learn about the new df\n",
        "df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GT6yKp1UcwJ",
        "outputId": "e7167844-2c04-467a-e4a2-6f463157946a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|summary|      Date|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
            "+-------+----------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|  count|      1258|              1258|             1258|             1258|             1258|             1258|             1258|\n",
            "|   mean|      null| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
            "| stddev|      null|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
            "|    min|2012-01-03|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n",
            "|    max|2016-12-30|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n",
            "+-------+----------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obervations:\n",
        "1. There are 1258 records in the database\n",
        "2."
      ],
      "metadata": {
        "id": "nm749-pR_lBn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-e42dU1Gqdf"
      },
      "source": [
        "## 2. Data Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for the double dtype columns, we will format all the data to 2 decimal places i.e. format_number()\n",
        "#we will pass each refomatting into a new df due to the immutable nature of spark DataFrames\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "df1 = df.withColumn('Open',F.format_number('Open', 2).cast(DoubleType()))\n",
        "df1.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkJUyZljVDiN",
        "outputId": "c1e62fe1-ea80-41a6-f4fb-b613f5ba7305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+---------+---------+------------------+--------+------------------+\n",
            "|      Date| Open|     High|      Low|             Close|  Volume|         Adj Close|\n",
            "+----------+-----+---------+---------+------------------+--------+------------------+\n",
            "|2012-01-03|59.97|61.060001|59.869999|         60.330002|12668800|52.619234999999996|\n",
            "|2012-01-04|60.21|60.349998|59.470001|59.709998999999996| 9593300|         52.078475|\n",
            "|2012-01-05|59.35|59.619999|58.369999|         59.419998|12768200|         51.825539|\n",
            "|2012-01-06|59.42|59.450001|58.869999|              59.0| 8069400|          51.45922|\n",
            "|2012-01-09|59.03|59.549999|58.919998|             59.18| 6679300|51.616215000000004|\n",
            "+----------+-----+---------+---------+------------------+--------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2= df1.withColumn('High', F.format_number('High', 2).cast(DoubleType()))\n",
        "df2.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATMZKVO0Zr1R",
        "outputId": "1d0e1e0d-1563-4041-d1f0-21d9f447542f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----+---------+------------------+--------+------------------+\n",
            "|      Date| Open| High|      Low|             Close|  Volume|         Adj Close|\n",
            "+----------+-----+-----+---------+------------------+--------+------------------+\n",
            "|2012-01-03|59.97|61.06|59.869999|         60.330002|12668800|52.619234999999996|\n",
            "|2012-01-04|60.21|60.35|59.470001|59.709998999999996| 9593300|         52.078475|\n",
            "|2012-01-05|59.35|59.62|58.369999|         59.419998|12768200|         51.825539|\n",
            "|2012-01-06|59.42|59.45|58.869999|              59.0| 8069400|          51.45922|\n",
            "|2012-01-09|59.03|59.55|58.919998|             59.18| 6679300|51.616215000000004|\n",
            "+----------+-----+-----+---------+------------------+--------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3=df2.withColumn('Low', F.format_number('Low', 2).cast(DoubleType()))\n",
        "df3.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXYylaw2gIAA",
        "outputId": "ebb2b47b-803d-41ee-b31e-efbc3e1784b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----+-----+------------------+--------+------------------+\n",
            "|      Date| Open| High|  Low|             Close|  Volume|         Adj Close|\n",
            "+----------+-----+-----+-----+------------------+--------+------------------+\n",
            "|2012-01-03|59.97|61.06|59.87|         60.330002|12668800|52.619234999999996|\n",
            "|2012-01-04|60.21|60.35|59.47|59.709998999999996| 9593300|         52.078475|\n",
            "|2012-01-05|59.35|59.62|58.37|         59.419998|12768200|         51.825539|\n",
            "|2012-01-06|59.42|59.45|58.87|              59.0| 8069400|          51.45922|\n",
            "|2012-01-09|59.03|59.55|58.92|             59.18| 6679300|51.616215000000004|\n",
            "+----------+-----+-----+-----+------------------+--------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df4=df3.withColumn('Close', F.format_number('Close', 2).cast(DoubleType()))\n",
        "df4.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xadjuke1gSOl",
        "outputId": "805793bd-25a5-4d14-f664-88af9d90eacf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----+-----+-----+--------+------------------+\n",
            "|      Date| Open| High|  Low|Close|  Volume|         Adj Close|\n",
            "+----------+-----+-----+-----+-----+--------+------------------+\n",
            "|2012-01-03|59.97|61.06|59.87|60.33|12668800|52.619234999999996|\n",
            "|2012-01-04|60.21|60.35|59.47|59.71| 9593300|         52.078475|\n",
            "|2012-01-05|59.35|59.62|58.37|59.42|12768200|         51.825539|\n",
            "|2012-01-06|59.42|59.45|58.87| 59.0| 8069400|          51.45922|\n",
            "|2012-01-09|59.03|59.55|58.92|59.18| 6679300|51.616215000000004|\n",
            "+----------+-----+-----+-----+-----+--------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stocks=df4.withColumn('Adj Close', F.format_number('Adj Close', 2).cast(DoubleType()))\n",
        "stocks.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah1R5Ulrga0Q",
        "outputId": "066a7d1f-1796-414a-a87e-52adf9d18e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----+-----+-----+--------+---------+\n",
            "|      Date| Open| High|  Low|Close|  Volume|Adj Close|\n",
            "+----------+-----+-----+-----+-----+--------+---------+\n",
            "|2012-01-03|59.97|61.06|59.87|60.33|12668800|    52.62|\n",
            "|2012-01-04|60.21|60.35|59.47|59.71| 9593300|    52.08|\n",
            "|2012-01-05|59.35|59.62|58.37|59.42|12768200|    51.83|\n",
            "|2012-01-06|59.42|59.45|58.87| 59.0| 8069400|    51.46|\n",
            "|2012-01-09|59.03|59.55|58.92|59.18| 6679300|    51.62|\n",
            "+----------+-----+-----+-----+-----+--------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Next we need to create a new data frame with a column called HV Ratio that is the ratio of the\n",
        "# High Price versus volume of stock traded for a day\n",
        "\n",
        "hv_stocks = stocks.withColumn('HV Ratio', F.format_number(F.col('High')/F.col('Volume'),6))\n",
        "hv_stocks.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWBmlqOugs1W",
        "outputId": "9b8349c6-3cab-4c43-9c1e-0c2059df480f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----+-----+-----+--------+---------+--------+\n",
            "|      Date| Open| High|  Low|Close|  Volume|Adj Close|HV Ratio|\n",
            "+----------+-----+-----+-----+-----+--------+---------+--------+\n",
            "|2012-01-03|59.97|61.06|59.87|60.33|12668800|    52.62|0.000005|\n",
            "|2012-01-04|60.21|60.35|59.47|59.71| 9593300|    52.08|0.000006|\n",
            "|2012-01-05|59.35|59.62|58.37|59.42|12768200|    51.83|0.000005|\n",
            "|2012-01-06|59.42|59.45|58.87| 59.0| 8069400|    51.46|0.000007|\n",
            "|2012-01-09|59.03|59.55|58.92|59.18| 6679300|    51.62|0.000009|\n",
            "+----------+-----+-----+-----+-----+--------+---------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn56TRA_iW-9"
      },
      "source": [
        "## 3. Data Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q1: What day had the Peak High in Price?\n",
        "\n",
        "peak_price = hv_stocks.agg({\"High\": \"max\"}).collect()[0][0]\n",
        "high = hv_stocks.filter(hv_stocks.High == peak_price)\n",
        "high.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO8xftmsicMH",
        "outputId": "f62d03c9-6837-4b67-a188-947840722321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+-----+-----+-----+-------+---------+--------+\n",
            "|      Date|Open| High|  Low|Close| Volume|Adj Close|HV Ratio|\n",
            "+----------+----+-----+-----+-----+-------+---------+--------+\n",
            "|2015-01-13|90.8|90.97|88.93|89.31|8215400|    83.83|0.000011|\n",
            "+----------+----+-----+-----+-----+-------+---------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q2: What is the mean of the Close column?\n",
        "close_mean = hv_stocks.agg({'Close': 'mean'}).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2C9OBu5kVvE",
        "outputId": "9f1c0f85-65c7-47ab-fd9e-fd81c728cb9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|       avg(Close)|\n",
            "+-----------------+\n",
            "|72.38844992050863|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q3: What is the max and min of the Volume column?\n",
        "peak_volume = hv_stocks.agg({\"Volume\": \"max\"}).show()\n",
        "min_volume = hv_stocks.agg({\"Volume\": \"min\"}).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKYIoRAvmRpf",
        "outputId": "9fe3be1e-e344-4e35-b14c-13983eefe75b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|max(Volume)|\n",
            "+-----------+\n",
            "|   80898100|\n",
            "+-----------+\n",
            "\n",
            "+-----------+\n",
            "|min(Volume)|\n",
            "+-----------+\n",
            "|    2094900|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q4: How many days was the Close lower than 60 dollars?\n",
        "low_close= hv_stocks.filter(hv_stocks.Close < 60).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnPHncnrpR3Z",
        "outputId": "efef24f5-6813-4831-fadf-3ed9efd73c61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----+-----+-----+--------+---------+--------+\n",
            "|      Date| Open| High|  Low|Close|  Volume|Adj Close|HV Ratio|\n",
            "+----------+-----+-----+-----+-----+--------+---------+--------+\n",
            "|2012-01-04|60.21|60.35|59.47|59.71| 9593300|    52.08|0.000006|\n",
            "|2012-01-05|59.35|59.62|58.37|59.42|12768200|    51.83|0.000005|\n",
            "|2012-01-06|59.42|59.45|58.87| 59.0| 8069400|    51.46|0.000007|\n",
            "|2012-01-09|59.03|59.55|58.92|59.18| 6679300|    51.62|0.000009|\n",
            "|2012-01-10|59.43|59.71|58.98|59.04| 6907300|    51.49|0.000009|\n",
            "|2012-01-11|59.06|59.53|59.04| 59.4| 6365600|    51.81|0.000009|\n",
            "|2012-01-12|59.79| 60.0| 59.4| 59.5| 7236400|     51.9|0.000008|\n",
            "|2012-01-13|59.18|59.61|59.01|59.54| 7729300|    51.93|0.000008|\n",
            "|2012-01-17|59.87|60.11|59.52|59.85| 8500000|     52.2|0.000007|\n",
            "|2012-02-22|59.58| 59.9|58.37| 58.6|28630200|    51.11|0.000002|\n",
            "|2012-02-23|58.59| 58.9|58.21|58.54|14880300|    51.06|0.000004|\n",
            "|2012-02-24|58.75|58.95| 58.5|58.79| 9925900|    51.28|0.000006|\n",
            "|2012-02-27| 58.7|58.78|58.29|58.46|12258800|    50.99|0.000005|\n",
            "|2012-02-28|58.44| 59.1|58.35|58.93|10761900|     51.4|0.000005|\n",
            "|2012-02-29|58.84|59.33|58.72|59.08|11484400|    51.53|0.000005|\n",
            "|2012-03-01|59.36|59.42|58.64|58.82|16283900|     51.3|0.000004|\n",
            "|2012-03-02|58.99|59.28| 58.8|59.01| 9848100|    51.47|0.000006|\n",
            "|2012-03-05|58.96|59.59|58.75| 59.4| 9651000|    51.81|0.000006|\n",
            "|2012-03-06|59.04|59.22|58.75|58.97| 9057100|    51.43|0.000007|\n",
            "|2012-03-07|59.11|59.86|59.11|59.86|14916900|    52.21|0.000004|\n",
            "+----------+-----+-----+-----+-----+--------+---------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q5: What percentage of the time was the High greater than 80 dollars?\n",
        "total_days = hv_stocks.count()\n",
        "high_greater_80 = hv_stocks[hv_stocks['High'] > 80]\n",
        "days_high_greater_80 = high_greater_80.count()\n",
        "print('Total days:',total_days,'\\nNumber of days High was greater than 80:',days_high_greater_80)\n",
        "print('Percentage of days High was greater than 80: {}%'.format((days_high_greater_80/total_days) * 100))\n",
        "high_greater_80.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFRAzZ5W3gxU",
        "outputId": "1ceec4a0-828b-49b0-cf69-1a8875f63ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total days: 1258 \n",
            "Number of days High was greater than 80: 115\n",
            "Percentage of days High was greater than 80: 9.141494435612083%\n",
            "+----------+-----+-----+-----+-----+--------+---------+--------+\n",
            "|      Date| Open| High|  Low|Close|  Volume|Adj Close|HV Ratio|\n",
            "+----------+-----+-----+-----+-----+--------+---------+--------+\n",
            "|2013-11-25|80.06|80.57|79.91|80.43| 5670400|    73.22|0.000014|\n",
            "|2013-11-26|80.44|80.68|80.11|80.68| 5537800|    73.45|0.000015|\n",
            "|2013-11-27|80.55| 81.0|80.38|80.93| 4813300|    73.67|0.000017|\n",
            "|2013-11-29|81.17|81.35|80.82|81.01| 3447200|    73.75|0.000024|\n",
            "|2013-12-02|80.89|81.28|80.37|81.11| 6178400|    73.84|0.000013|\n",
            "|2013-12-03|81.21|81.33| 80.7|81.21| 7506400|    73.93|0.000011|\n",
            "|2013-12-04|80.64|81.37|79.91|80.22| 7641200|    73.45|0.000011|\n",
            "|2013-12-06|79.71|80.23|79.64|79.94| 5088100|     73.2|0.000016|\n",
            "|2013-12-09|80.24|80.43| 79.7|79.95| 4491600|    73.21|0.000018|\n",
            "|2014-11-10| 78.6|80.13|78.42|79.44|12640500|    74.15|0.000006|\n",
            "|2014-11-13|80.96|83.06|80.86|82.94|22812400|    77.41|0.000004|\n",
            "|2014-11-14|82.58|83.15| 82.1|82.96|10636600|    77.43|0.000008|\n",
            "|2014-11-17|82.58|83.72|82.53|83.57| 7993400|     78.0|0.000010|\n",
            "|2014-11-18| 83.5|83.92|83.34|83.79| 6096400|    78.21|0.000014|\n",
            "|2014-11-19|83.96|85.64|83.92|84.99|12189800|    79.33|0.000007|\n",
            "|2014-11-20|84.81|85.29|84.04|84.58| 7812700|    78.94|0.000011|\n",
            "|2014-11-21|85.34|85.44|84.58|84.65| 6649600|    79.01|0.000013|\n",
            "|2014-11-24|84.85|85.61|84.77| 85.4| 7995500|    79.71|0.000011|\n",
            "|2014-11-25| 85.5|85.51|84.39|84.95| 6675500|    79.29|0.000013|\n",
            "|2014-11-26| 84.9|85.11|84.48|84.98| 3942800|    79.32|0.000022|\n",
            "+----------+-----+-----+-----+-----+--------+---------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q6: What is the Pearson correlation between High and Volume?\n",
        "# hv_stocks.dtypes\n",
        "hv_stocks.corr('High','Volume')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvzzWs1M3ndr",
        "outputId": "16a74994-c80d-4092-a4e3-090e49c24ee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.33843260582148915"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q7: What is the max High per year?\n",
        "hv_stocks.groupby(F.date_format('Date','yyyy').alias('Year')).agg({'High': 'max'}).sort('Year').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDti11W83xiq",
        "outputId": "9c746b5e-cfbe-4e08-f7ee-6533b07385f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------+\n",
            "|Year|max(High)|\n",
            "+----+---------+\n",
            "|2012|     77.6|\n",
            "|2013|    81.37|\n",
            "|2014|    88.09|\n",
            "|2015|    90.97|\n",
            "|2016|    75.19|\n",
            "+----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q8: What is the average Close for each Calendar Month?\n",
        "hv_stocks.groupby(F.date_format('Date','MM').alias('Month')).agg({'Close': 'mean'}).sort('Month').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUY5kiVz31nE",
        "outputId": "c16674d4-5c20-4c3b-f66d-267c2e9a5853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------+\n",
            "|Month|       avg(Close)|\n",
            "+-----+-----------------+\n",
            "|   01|71.44801980198022|\n",
            "|   02|71.30680412371134|\n",
            "|   03|71.77794392523363|\n",
            "|   04|72.97361904761907|\n",
            "|   05|72.30971698113206|\n",
            "|   06|72.49537735849057|\n",
            "|   07|74.43971962616824|\n",
            "|   08|73.02981818181819|\n",
            "|   09|72.18411764705883|\n",
            "|   10|71.57854545454546|\n",
            "|   11|72.11108910891085|\n",
            "|   12|72.84792452830189|\n",
            "+-----+-----------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}